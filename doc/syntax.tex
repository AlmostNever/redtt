\documentclass{article}
\usepackage[colorlinks]{hyperref}
\usepackage{natbib}

\usepackage{fontawesome}
\usepackage{dingbat}

\usepackage{amssymb}


\usepackage[tt=false]{libertine}
\usepackage{microtype}
\usepackage{hyperref}
\usepackage{mathpartir}
\usepackage[dvipsnames]{xcolor}
\usepackage{fullpage}
\usepackage{manfnt}

\usepackage{mathtools}

\DeclarePairedDelimiter\Parens{\lparen}{\rparen}
\DeclarePairedDelimiter\Angles{\langle}{\rangle}
\DeclarePairedDelimiter\Squares{[}{]}

\DeclarePairedDelimiter\Braces{\lbrace}{\rbrace}
\DeclarePairedDelimiter\Pipes{\lvert}{\rvert}

\newcommand\Len[1]{\Pipes*{#1}}

\newtheorem{remark}{Remark}



\usepackage{stmaryrd}
\usepackage{wasysym}

\title{Cartesian Cubical Type Theory:\\ Reduction-Free Semantics and
  Definitional Equivalence} \author{Jon Sterling}

\newcommand\FmtKwd[1]{\mathsf{#1}}

\newcommand\DeclBox[1]{\framebox{$\displaystyle{}#1$}}
\newcommand\FmtThin[1]{{\color{ProcessBlue}#1}}

\newcommand\Thin[2]{{#1}\rightarrowtriangle{#2}}
\newcommand\IsThin[3]{\FmtThin{#1}:\Thin{#2}{#3}}

\newcommand\ThinId{\mathsf{id}}
\newcommand\ThinKeep[1]{\mbox{\leftthumbsdown}\!\!\rangle\!{#1}\!\langle\!\!\mbox{\rightthumbsdown}}
\newcommand\ThinSkip[1]{{#1}.\mbox{\faTrashO}}
\newcommand\ThinRep[2]{{#1}.\Squares*{{\normalcolor{}#2}}}

\newcommand\Tube[3]{{#1}={#2}\triangleright{#3}}
\newcommand\BTube[3]{{#1}={#2}\mathbin{\triangleright^+}{#3}}

\usepackage{xinttools}

\newcommand\FormatList[3]{%
  \xintFor ##1 in {#3} \do{%
    #1{##1}%
    \xintifForLast{}{#2}
  }
}



\newcommand\THIN{\mathbf{Thin}}
\newcommand\OpCat[1]{{#1}^{\mathsf{op}}}
\newcommand\SET{\mathbf{Set}}

\newcommand\Interval{\FmtKwd{dim}}
\newcommand\Bool{\FmtKwd{bool}}
\newcommand\Var[1]{\mathsf{v}_{#1}}

\newcommand\SortChk{\FmtKwd{chk}}
\newcommand\SortInf{\FmtKwd{inf}}

\newcommand\SortCofib{\FmtKwd{cofig}}
\newcommand\SortSys{\FmtKwd{sys}}
\newcommand\SortBSys{\FmtKwd{bsys}}


\newcommand\Tm[3]{{#1}\mid{#2}\vdash{#3}}
\newcommand\FmtTm[1]{{\color{Violet}#1}}
\newcommand\IsTm[3]{{#1}\vdash\FmtTm{#2}:{#3}}
\newcommand\IsChk[2]{\IsTm{#1}{#2}{\SortChk}}
\newcommand\IsInf[2]{\IsTm{#1}{#2}{\SortInf}}

\newcommand\TExp[2]{
  \FmtTm{
    \Parens*{
      \FmtKwd{#1}\
      \FormatList{}{\ }{#2}
    }
  }
}


\newcommand\FmtVal[1]{{\color{Red}{#1}}}

\newcommand\VExp[2]{
  \FmtVal{
    \Parens*{
      \FmtKwd{#1}\
      \FormatList{}{\ }{#2}
    }
  }
}


\newcommand\EvalClo[2]{\FmtVal{#1}\Downarrow\FmtVal{#2}}
\newcommand\Eval[5]{\FmtThin{#2}*\FmtVal{#3}\vDash\FmtTm{#4}\mathrel{\Downarrow_{\FmtThin{#1}}}\FmtVal{#5}}
\newcommand\Reflect[3]{\FmtVal{#1}\ni\FmtVal{#2}\uparrow\FmtVal{#3}}
\newcommand\Apply[3]{\FmtVal{#1}\mathrel{@}\FmtVal{#2}\Downarrow\FmtVal{#3}}
\newcommand\InstClo[3]{\FmtVal{#1}\bullet\FmtVal{#2}\Downarrow\FmtVal{#3}}
\newcommand\ThinVal[2]{\widehat{\FmtThin{#1}}\Parens*{\FmtVal{#2}}}
\newcommand\Car[2]{\FmtVal{#1}\ \mathbf{car}\Downarrow\FmtVal{#2}}
\newcommand\Cdr[2]{\FmtVal{#1}\ \mathbf{cdr}\Downarrow\FmtVal{#2}}


\begin{document}
\maketitle

The purpose of these notes is to develop a reduction-free semantics
and algorithmic theory of definitional equivalence for cartesian
cubical type theory which is as efficient and carefully organized as
possible: in particular, we arrange to calculate all substitutions and
renamings lazily using environments and closures. Our definition of
both the syntactic and the semantic domain is strongly scoped, which
makes it easier to verify the that we have correctly resolved the
contradiction between the name and the location of a bound variable.

In these notes, we use colors to distinguish objects of different
(meta) sorts from each other, in order to avoid getting lost in a
hurricane of superscripts. As such, $\FmtTm{M}$ and $\FmtVal{M}$ are
to be understood as distinct schematic variables. Some of the ideas
for dealing with evaluation under dimension binders come from joint
work with Favonia and Daniel Gratzer and Carlo Angiuli; the idea of
generalized thinnings comes from Conor McBride (as far as I am aware).

\section{Defunctionalized NbE}

We develop evaluation and quotation judgments for Cartesian Cubical
Type Theory inspired by normalization by evaluation (NbE), in its
\emph{defunctionalized} variant. Often NbE is presented using domain
models and binding is represented using meta-level functions, and
evaluation and quotation are intertwined. My perspective is that the
correct theoretical development of a concept should mirror a practical
implementation; therefore, we choose to suspend in syntax the
structure of the NbE algorithm, using closures and shifts in the
semantic domain. In this style of NbE, the evaluation function is
called from the quotation function, but not vice versa.

The state of the art in the science of normalization by evaluation is found in
Andreas Abel's habilitation thesis~\citep{abel:2013}; other relevant sources are included in the bibliography of these notes.

\paragraph{Why NbE?}

The old practice of regarding computation as a kind of rewriting
system does not scale cleanly to calculation with
indeterminates. Inefficiency is not the only nail in the coffin of the
old heroic attempts to unleash open computation by attacking a term
with rewriting rules; it is typical of \emph{rewriting-theory
  dogmato-revisionism} to account for only one half of the dialectic
of open term behavior: indeed, any account of computation for open
terms of negative type must explain not only reduction, but also
expansion.

\textbf{I want to clarify that my main goal is not to acquire a normalization
function.} I am trying to decide definitional equivalence, and the simplest way
to do this algorithmically follows the structure of NbE very closely
(regardless of whether it is instantiated to yield a normalization function).


\section{Thinnings}

Thinnings are a defunctionalized representation of weakenings which
capture the idea of deleting some variables from within a context;
these correspond to the \emph{order-preserving embeddings} of Chapman.
%
We choose a representation of thinnings which lends itself to
efficient calculation, but is not canonical; therefore, any operation
on thinnings must be proved to be respect the algebraic laws of
thinnings in order to be well-defined.
\begin{mathparpagebreakable}
  \DeclBox{
    \IsThin{f}{n}{m}
  }
  \\
  \inferrule{
  }{
    \IsThin{\ThinId}{n}{n}
  }
  \and
  \inferrule{
    \IsThin{f}{n}{m}
  }{
    \IsThin{\ThinKeep{f}}{n+1}{m+1}
  }
  \and
  \inferrule{
    \IsThin{f}{n}{m}
  }{
    \IsThin{\ThinSkip{f}}{n+1}{m}
  }
\end{mathparpagebreakable}

We will write $\THIN$ for the category of thinnings
induced by the above.

\section{Terms}

Terms are classified by sorts $\tau\in\Braces*{\SortChk,\SortInf}$; we
will write the judgment $\IsTm{n}{M}{\tau}$ to mean that $\FmtTm{M}$
is a term of sort $\tau$ with $n$ variables. In the term language,
variables are managed using De Bruijn indices. An illustrative
fragment of the syntax is presented below. (TODO)

\begin{mathparpagebreakable}
  \DeclBox{
    \IsTm{n}{M}{\tau}
  }
  \\
  \and
  \inferrule[TmVar]{
    i<n
  }{
    \IsInf{n}{\Var{i}}
  }
  \and
  \inferrule[TmPi]{
    \IsChk{n}{A}
    \\
    \IsChk{n+1}{B}
  }{
    \IsChk{n}{
      \TExp{\Pi}{A,B}
    }
  }
  \and
  \inferrule[TmSg]{
    \IsChk{n}{A}
    \\
    \IsChk{n+1}{B}
  }{
    \IsChk{n}{
      \TExp{\Sigma}{A,B}
    }
  }
  \and
  \inferrule[TmLam]{
    \IsChk{n+1}{M}
  }{
    \IsChk{n}{\TExp{\lambda}{M}}
  }
  \and
  \inferrule[TmCons]{
    \IsChk{n}{M}
    \\
    \IsChk{n}{N}
  }{
    \IsChk{n}{\TExp{cons}{M,N}}
  }
  \and
  \inferrule[TmCar]{
    \IsInf{n}{R}
  }{
    \IsInf{n}{\TExp{car}{R}}
  }
  \and
  \inferrule[TmCdr]{
    \IsInf{n}{R}
  }{
    \IsInf{n}{\TExp{cdr}{R}}
  }
  \and
  \inferrule[TmDim0]{
  }{
    \IsChk{n}{0}
  }
  \and
  \inferrule[TmDim1]{
  }{
    \IsChk{n}{1}
  }
  \and
  \inferrule[TmUp]{
    \IsInf{n}{R}
  }{
    \IsChk{n}{\TExp{\uparrow}{R}}
  }
  \and
  \inferrule[TmApp]{
    \IsInf{n}{R}
    \\
    \IsChk{n}{M}
  }{
    \IsInf{n}{\TExp{@}{R,M}}
  }
  \and
  \inferrule[TmDown]{
    \IsChk{n}{A}
    \\
    \IsChk{n}{M}
  }{
    \IsInf{n}{\TExp{\downarrow}{A,M}}
  }
  \and
  \inferrule[TmCoe]{
    \IsChk{n}{I}
    \\
    \IsChk{n}{J}
    \\
    \IsChk{n+1}{A}
    \\
    \IsChk{n}{M}
  }{
    \IsInf{n}{
      \TExp{coe}{
        I,
        J,
        A,
        M
      }
    }
  }
  \and
  \inferrule[TmSys]{
    \overline{
      \IsChk{n}{I_i}
    }
    \\
    \overline{
      \IsChk{n}{J_i}
    }
    \\
    \overline{
      \IsChk{n}{M_i}
    }
  }{
    \IsTm{n}{
      \Squares*{
        \overline{
          \Tube{I_i}{J_i}{M_i}
        }
      }
    }{\SortSys}
  }
  \and
  \inferrule[TmBSys]{
    \overline{
      \IsChk{n}{I_i}
    }
    \\
    \overline{
      \IsChk{n}{J_i}
    }
    \\
    \overline{
      \IsChk{n+1}{M_i}
    }
  }{
    \IsTm{n}{
      \Squares*{
        \overline{
          \BTube{I_i}{J_i}{M_i}
        }
      }
    }{\SortBSys}
  }
  \and
  \inferrule[TmExtend]{
    \IsChk{n}{A}
    \\
    \IsTm{n}{S}{\SortSys}
  }{
    \IsChk{n}{
      \TExp{ext}{
        A,
        S
      }
    }
  }
  \and
  \inferrule[TmHCom]{
    \IsChk{n}{I}
    \\
    \IsChk{n}{J}
    \\
    \IsChk{n}{A}
    \\
    \IsChk{n}{M}
    \\
    \IsTm{n}{S}{\SortBSys}
  }{
    \IsInf{n}{
      \TExp{hcom}{
        I,
        J,
        A,
        M,
        S
      }
    }
  }
\end{mathparpagebreakable}


\section{Semantic Domain}

The semantic domain of our language is really another syntax, in which
variables are replaced by semantic indeterminates (represented as De
Bruijn levels), and atoms remain represented as De Bruijn indices. The
semantic domain captures the weak-head normal forms of our language;
because we intend to develop a substitution-free evaluation semantics using
environments, we must naturally employ a notion of \emph{closure}.

\newcommand\SortCan{\FmtKwd{can}}
\newcommand\SortNeu{\FmtKwd{neu}}
\newcommand\SortClo{\FmtKwd{clo}}
\newcommand\SortBClo{\FmtKwd{bclo}}
\newcommand\SortEnv[1]{\FmtKwd{env}_{#1}}
\newcommand\IsVal[2]{\Vdash\FmtVal{#1}:{#2}}

\newcommand\Clo[4]{
  \text{(TODO)}
}

\newcommand\BClo[4]{
  \text{(TODO)}
}


Values are classified by sorts
$\tau\in\Braces*{\SortCan,\SortNeu,\SortEnv{l},\SortClo,\SortBClo}$; for
such a sort $\tau$, we will write $\IsVal{M}{\tau}$ to mean that
$\FmtVal{M}$ is a value of sort $\tau$. We no longer
track the number of variables, because these are replaced by
indeterminates in the form of De Bruijn levels (which have an absolute
reference).

\begin{mathparpagebreakable}
  \DeclBox{
    \IsVal{M}{\tau}
  }
  \\
  \inferrule[ValGen]{
  }{
    \IsVal{\Var{l}}{\SortNeu}
  }
  \and
  \inferrule[ValUp]{
    \IsVal{A}{\SortCan}
    \\
    \IsVal{R}{\SortNeu}
  }{
    \IsVal{
      \VExp{\uparrow}{A,R}
    }{\SortCan}
  }
  \and
  \inferrule[ValEnv]{
    \forall{i<l}.\ \IsVal{M_i}{\SortCan}
  }{
    \IsVal{\Squares{M_i}_{i<l}}{\SortEnv{l}}
  }
  \\
  \inferrule[ValPi]{
    \IsVal{A}{\SortClo}
    \\
    \IsVal{A}{\SortBClo}
  }{
    \IsVal{
      \VExp{\Pi}{A,B}
    }{\SortCan}
  }
  \and
  \inferrule[ValLam]{
    \IsVal{M}{\SortClo}
  }{
    \IsVal{\VExp{\lambda}{M}}{\SortCan}
  }
  \and
  \inferrule[ValApp]{
    \IsVal{R}{\SortNeu}
    \\
    \IsVal{M}{\SortCan}
  }{
    \IsVal{\VExp{@}{R,M}}{\SortNeu}
  }
  \and
  \inferrule[ValCons]{
    \IsVal{M}{\SortClo}
    \\
    \IsVal{N}{\SortClo}
  }{
    \IsVal{\VExp{cons}{M,N}}{\SortCan}
  }
  \and
  \inferrule[ValCar]{
    \IsVal{R}{\SortNeu}
  }{
    \IsVal{\VExp{car}{R}}{\SortNeu}
  }
  \and
  \inferrule[ValCdr]{
    \IsVal{R}{\SortNeu}
  }{
    \IsVal{\VExp{cdr}{R}}{\SortNeu}
  }
\end{mathparpagebreakable}


The syntax of values can be reindexed contravariantly along
thinnings $\IsThin{f}{m}{n}$; the
reindexing action is renaming.

\begin{remark}[Reification and reflection]

  In modern NbE, eta expansion is divided into two phases called
  ``reification'' and ``reflection'', which occur entirely at the level of the
  semantic domain. Reflection $\uparrow$ embeds the neutral values into the
  canonical values, and reification $\downarrow$ embeds the canonical values
  into the normal values.
%
  In this presentation so far, we have not yet phrased things in terms of
  reification and ``normal values''; I will change this shortly.

\end{remark}


\begin{remark}[Extension with singleton and extension types]

  Reflection of neutral values into canonical values is present in the semantic
  domain as a ``free'' constructor, rather than as an operation. This is
  because reflection is calculated lazily.

  To extend with constructs like singleton and extension types, it is necessary
  to impose an equational law on reflection: basically, reflecting a neutral of
  singleton type should project out a canonical value from the singleton type.
  This is done using an auxiliary judgment to reflect neutral values.


\end{remark}


\section{Evaluation}


At a high level, evaluation takes terms to values; at a finer-grained
level, however, we will evaluate with respect to a thinning
$\FmtThin{g}$ and an environment $\FmtVal{\rho}$ together with a
thinning $\FmtThin{f}$; this allows us to avoid actually executing
thinnings and substitutions until the last moment possible. In fact,
the preceding sentence can be rephrased as construing evaluation as a
relation $\EvalClo{M_\SortClo}{M_\SortCan}$ where
$\IsVal{M_\SortClo}{\SortClo}$ and
$\IsVal{M_\SortCan}{\SortCan}$.

We will write $\Eval{g}{f}{\rho}{M}{M}$ as a notation for
$\EvalClo{\Clo{g}{f}{\rho}{M}}{M}$, when it is well-formed:


\begin{mathparpagebreakable}
  \DeclBox{
    \inferrule[JdgEval]{
      \IsThin{g}{o}{n}
      \\
      \IsThin{f}{n}{m}
      \\
      \IsVal{m}{\rho}{\SortEnv{l}}
      \\
      \IsTm{n}{l}{M}{\tau}
      \\
      \IsVal{o}{M}{\SortCan}
    }{
      \DeclBox{
        \Eval{g^+}{f^+}{\rho^+}{M^+}{M^-}
      }
    }
  }
  \\
  \inferrule[EvalVar]{}{
    \Eval{g}{f}{\rho}{\Var{l}}{
      \ThinVal{
        g\circ{}f
      }{\rho_l}
    }
  }
  \and
  \inferrule[EvalPi]{}{
    \Eval{g}{f}{\rho}{
      \TExp{\Pi}{A,B}
    }{
      \VExp{\Pi}{
        \Clo{g}{f}{\rho}{A},
        \BClo{g}{f}{\rho}{B}
      }
    }
  }
  \and
  \inferrule[EvalSg]{}{
    \Eval{g}{f}{\rho}{
      \TExp{\Sigma}{A,B}
    }{
      \VExp{\Sigma}{
        \Clo{g}{f}{\rho}{A},
        \BClo{g}{f}{\rho}{B}
      }
    }
  }
  \and
  \inferrule[EvalLam]{}{
    \Eval{g}{f}{\rho}{
      \TExp{\lambda}{M}
    }{
      \VExp{\lambda}{
        \BClo{g}{f}{\rho}{M}
      }
    }
  }
  \and
  \and
  \inferrule[EvalUp]{
    \Eval{g}{f}{\rho}{R}{M}
  }{
    \Eval{g}{f}{\rho}{
      \TExp{\uparrow}{R}
    }{
      M
    }
  }
  \and
  \inferrule[EvalDown]{
    \Eval{g}{f}{\rho}{M}{M}
  }{
    \Eval{g}{f}{\rho}{
      \TExp{\downarrow}{A,M}
    }{M}
  }
  \and
  \inferrule[EvalCoe]{
    \Eval{g}{f}{\rho}{I}{I}
    \\
    \Eval{g}{f}{\rho}{J}{J}
    \\
    \Eval{\ThinKeep{g}}{\ThinSkip{f}}{\rho}{A}{A}
    \\
    \Eval{g}{f}{\rho}{M}{M}
  }{
    \Eval{g}{f}{\rho}{
      \TExp{coe}{I,J,A,M}
    }{
      \VExp{coe}{
        I,
        J,
        A,
        M
      }
    }
  }
  \and
  \inferrule[EvalApp]{
    \Eval{g}{f}{\rho}{R}{M_{\mathsf{fun}}}
    \\
    \Eval{g}{f}{\rho}{M}{M_{\mathsf{arg}}}
    \\
    \Apply{M_{\mathsf{fun}}}{M_{\mathsf{arg}}}{N}
  }{
    \Eval{g}{f}{\rho}{
      \TExp{@}{
        R,
        M
      }
    }{
      N
    }
  }
  \and
  \inferrule[EvalCar]{
    \Eval{g}{f}{\rho}{R}{M}
    \\
    \Car{M}{N}
  }{
    \Eval{g}{f}{\rho}{
      \TExp{car}{R}
    }{N}
  }
  \and
  \inferrule[EvalCdr]{
    \Eval{g}{f}{\rho}{R}{M}
    \\
    \Cdr{M}{N}
  }{
    \Eval{g}{f}{\rho}{
      \TExp{cdr}{R}
    }{N}
  }
\end{mathparpagebreakable}

We will also require a judgment for evaluating systems; this will be
interesting, because the cells associated to false equations must be replaced
with an \emph{abort}. (TODO)


\begin{mathparpagebreakable}
  \DeclBox{
    \inferrule[JdgInst]{
      \IsVal{M}{\SortBClo}
      \\
      \IsVal{N}{\SortCan}
      \\
      \IsVal{O}{\SortCan}
    }{
      \DeclBox{\InstClo{M^+}{N^+}{O^-}}
    }
  }
  \and
  \inferrule[InstBClo]{
    \Eval{g}{f}{\Squares*{N,\rho}}{M}{O}
  }{
    \InstClo{
      \BClo{g}{f}{\rho}{M}
    }{N}{O}
  }
\end{mathparpagebreakable}

\begin{mathparpagebreakable}
  \DeclBox{
    \inferrule[JdgReflect]{
      \IsVal{A}{\SortCan}
      \\
      \IsVal{R}{\SortNeu}
      \\
      \IsVal{M}{\SortCan}
    }{
      \DeclBox{\Reflect{A^+}{R^+}{M^-}}
    }
  }
  \\
  \inferrule[ReflectExtTrue]{
    k \text{ minimal such that } \FmtVal{I_k}\equiv\FmtVal{J_k}
    \\
    \EvalClo{M_k^\SortClo}{M_k^\SortCan}
  }{
    \Reflect{
      \VExp{ext}{
        A,
        \Squares*{
          \overline{
            \Tube{I_i}{J_i}{M_i^\SortClo}
          }
        }
      }
    }{
      R
    }{
      M_k^\SortCan
    }
  }
  \and
  \inferrule[ReflectOtherwise]{
    \text{(otherwise)}
  }{
    \Reflect{A}{R}{
      \VExp{\uparrow}{A,R}
    }
  }
\end{mathparpagebreakable}

\begin{mathparpagebreakable}
  \DeclBox{
    \inferrule[JdgApply]{
      \IsVal{M}{\SortCan}
      \\
      \IsVal{N}{\SortCan}
      \\
      \IsVal{O}{\SortCan}
    }{
      \DeclBox{\Apply{M^+}{N^+}{O^-}}
    }
  }
  \\
  \inferrule[ApplyLam]{
    \InstClo{M}{N}{O}
  }{
    \Apply{\VExp{\lambda}{M}}{N}{O}
  }
  \and
  \inferrule[ApplyUpPi]{
    \InstClo{B_\SortClo}{N}{B_\SortCan}
    \\
    \Reflect{B_\SortCan}{
      \VExp{@}{R,N}
    }{M}
  }{
    \Apply{
      \VExp{\uparrow}{
        \VExp{\Pi}{A_\SortClo,B_\SortBClo},
        R
      }
    }{N}{M}
  }
\end{mathparpagebreakable}

Observe how in \textsc{ApplyCoePi}, we used in an essential way the
fact that the dimension binder of $\FmtKwd{coe}$ abstracts an
\emph{atom} rather than a \emph{variable}; in the semantic domain,
this means that we may name this dimension using an atom of the $0$th
De Bruijn index. This is essential: if we had bound a variable rather
than an atom, it would be impossible from this point of view of the
application judgment to know the De Bruijn level of the bound
dimension.

The cost of this solution to the problem of evaluating under binders
is that we must be careful to apply thinnings in all the right
places. It is easy to verify that the semantic term is well-formed
using the strongly-scoped term formation rules given; moreover, the
thinnings will generally be inexpensive, since they tend to pile up on
closures.

\begin{mathparpagebreakable}
  \DeclBox{
    \inferrule[JdgCar]{
      \IsVal{M}{\SortCan}
      \\
      \IsVal{N}{\SortCan}
    }{
      \DeclBox{
        \Car{M^+}{N^-}
      }
    }
  }
  \\
  \inferrule[CarCons]{
    \EvalClo{M_\SortClo}{M_\SortCan}
  }{
    \Car{
      \VExp{cons}{M_\SortClo,N_\SortClo}
    }{M_\SortCan}
  }
  \and
  \inferrule[CarUpSg]{
    \EvalClo{A_\SortClo}{A_\SortCan}
    \\
    \Reflect{A_\SortCan}{
      \VExp{car}{R}
    }{M}
  }{
    \Car{
      \VExp{\uparrow}{
        \VExp{\Sigma}{A_\SortClo,B_\SortBClo},
        R
      }
    }{M}
  }
  \and
  \inferrule[CarCoeSg]{
    \EvalClo{A_\SortClo}{A_\SortCan}
    \\
    \Car{M}{N}
  }{
    \Car{
      \VExp{coe}{
        I,
        J,
        \VExp{\Sigma}{
          A_\SortClo,
          B_\SortBClo%
        },
        M
      }
    }{
      \VExp{coe}{
        I,
        J,
        A_\SortCan,
        N
      }
    }
  }
\end{mathparpagebreakable}

\begin{mathparpagebreakable}
  \DeclBox{
    \inferrule[JdgCdr]{
      \IsVal{M}{\SortCan}
      \\
      \IsVal{N}{\SortCan}
    }{
      \DeclBox{
        \Cdr{M^+}{N^-}
      }
    }
  }
  \\
  \inferrule[CdrCons]{
    \EvalClo{N_\SortClo}{N_\SortCan}
  }{
    \Cdr{
      \VExp{cons}{M_\SortClo,N_\SortClo}
    }{N_\SortCan}
  }
  \and
  \inferrule[CdrUpSg]{
    \Car{
      \VExp{\uparrow}{
        \VExp{\Sigma}{A_\SortClo,B_\SortBClo},
        R
      }
    }{M}
    \\
    \InstClo{B_\SortBClo}{M}{B_\SortCan}
    \\
    \Reflect{B_\SortCan}{
      \VExp{cdr}{R}
    }{N}
  }{
    \Cdr{
      \VExp{\uparrow}{
        \VExp{\Sigma}{A_\SortClo,B_\SortBClo},
        R
      }
    }{N}
  }
\end{mathparpagebreakable}


\section{Quotation}

\newcommand\QuoteCan[4]{
  \FmtVal{#1}\vDash\FmtVal{#2}\ni\FmtVal{#3}\Uparrow\FmtTm{#4}
}

\newcommand\QuoteNeu[4]{
  \FmtVal{#1}\vDash\FmtVal{#2}\Uparrow\FmtTm{#3}\in\FmtVal{#4}
}

\newcommand\SortCtx[1]{\FmtKwd{ctx}_{#1}}

\subsection{Semantic contexts}

\begin{mathparpagebreakable}
  \DeclBox{
    \inferrule[JdgCtx]{}{
      \DeclBox{\IsVal{n^-}{\Gamma}{\SortCtx{l^-}}}
    }
  }
  \\
  \inferrule[CtxNil]{}{
    \IsVal{0}{\cdot}{\SortCtx{0}}
  }
  \and
  \inferrule[CtxExtVar]{
    \IsVal{\Gamma}{\SortCtx{l}}
    \\
    \IsVal{A}{\SortCan}
  }{
    \IsVal{\Gamma.A}{\SortCtx{l+1}}
  }
  \and
  \inferrule[CtxExtAtom]{
    \IsVal{\Gamma}{\SortCtx{l}}
    \\
    \IsVal{A}{\SortCan}
  }{
    \IsVal{n+1}{\Gamma.\nabla{}A}{\SortCtx{l}}
  }
\end{mathparpagebreakable}

\subsection{Quotation and Definitional Equivalence}

To start with, I define a quotation from semantic values to syntactic
terms; together with evaluation, this generates a theory of
definitional equivalence.


\begin{mathparpagebreakable}
  \DeclBox{
    \inferrule[JdgQuoteCan]{
      \IsVal{\Gamma}{\SortCtx{l}}
      \\
      \IsVal{A}{\SortCan}
      \\
      \IsVal{M}{\SortCan}
      \\
      \IsTm{n}{l}{M}{\SortChk}
    }{
      \DeclBox{\QuoteCan{\Gamma^+}{A^+}{M^+}{M^-}}
    }
  }
  \and
  \DeclBox{
    \inferrule[JdgQuoteNeu]{
      \IsVal{\Gamma}{\SortCtx{l}}
      \\
      \IsVal{R}{\SortNeu}
      \\
      \IsTm{n}{l}{R}{\SortInf}
      \\
      \IsVal{A}{\SortCan}
    }{
      \DeclBox{\QuoteNeu{\Gamma^+}{R^+}{R^-}{A^-}}
    }
  }
  \\
  \inferrule[QuotePi]{
    \EvalClo{A_\SortClo}{A_\SortCan}
    \\
    \QuoteCan{\Gamma}{C}{A_\SortCan}{A}
    \\
    \Reflect{A_\SortCan}{\Var{\Len{\Gamma}}}{M}
    \\
    \InstClo{B_\SortClo}{M}{B_\SortCan}
    \\
    \QuoteCan{\Gamma.A_\SortCan}{C}{B_\SortCan}{B}
  }{
    \QuoteCan{\Gamma}{C}{
      \VExp{\Pi}{A_\SortClo,B_\SortBClo}
    }{
      \TExp{\Pi}{
        A,
        B
      }
    }
  }
  \and
  \inferrule[QuoteLam]{
    \EvalClo{A}{A_\SortCan}
    \\
    \Reflect{A_\SortCan}{\Var{\Len{\Gamma}}}{N}
    \\
    \InstClo{B}{N}{B_\SortCan}
    \\
    \Apply{M}{N}{O}
    \\
    \QuoteCan{\Gamma.A_\SortCan}{B_\SortCan}{O}{O}
  }{
    \QuoteCan{\Gamma}{
      \VExp{\Pi}{A,B}
    }{M}{
      \TExp{\lambda}{O}
    }
  }
  \and
  \inferrule[QuoteCoeBool]{
    \QuoteCan{\Gamma}{\Bool}{M}{M}
  }{
    \QuoteCan{\Gamma}{C}{
      \VExp{coe}{
        I,
        J,
        \Bool,
        M
      }
    }{
      M
    }
  }
  \and
  \inferrule[QuoteApPi]{
    \QuoteNeu{\Gamma}{R}{R}{
      \VExp{\Pi}{A_\SortClo,B_\SortBClo}
    }
    \\
    \EvalClo{A_\SortClo}{A_\SortCan}
    \\
    \InstClo{B_\SortBClo}{N}{B_\SortCan}
    \\
    \QuoteCan{\Gamma}{A_\SortCan}{N}{N}
  }{
    \QuoteNeu{\Gamma}{
      \VExp{@}{R,N}
    }{
      \TExp{@}{R,N}
    }{
      B_\SortCan%
    }
  }
  \and
  \inferrule[QuoteCar]{
    \QuoteNeu{\Gamma}{R}{R}{
      \VExp{\Sigma}{A_\SortClo,B_\SortBClo}
    }
    \\
    \EvalClo{A_\SortClo}{A_\SortCan}
  }{
    \QuoteNeu{\Gamma}{
      \VExp{car}{R}
    }{
      \TExp{car}{R}
    }{A_\SortCan}
  }
  \and
  \inferrule[QuoteCdr]{
    \QuoteNeu{\Gamma}{R}{R}{
      \VExp{\Sigma}{A_\SortClo,B_\SortBClo}
    }
    \\
    \EvalClo{A_\SortClo}{A_\SortCan}
    \\
    \Reflect{A_\SortCan}{
      \VExp{car}{R}
    }{M}
    \\
    \InstClo{B_\SortBClo}{M}{B_\SortCan}
  }{
    \QuoteNeu{\Gamma}{
      \VExp{cdr}{R}
    }{
      \TExp{cdr}{R}
    }{
      B_\SortCan%
    }
  }
\end{mathparpagebreakable}

\nocite{abel-coquand-pagano:2009, abel-vezzosi-winterhalter:2017, altenkirch-chapman:2009, abcfhl:2017, cchm:2017, altenkirch-mcbride:2006, altenkirch-mcbride-swierstra:2007, stone-harper:2006, angiuli-favonia-harper:2017}

\bibliographystyle{plainnat}
\bibliography{references/refs}

\end{document}
